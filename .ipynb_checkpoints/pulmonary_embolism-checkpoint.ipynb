{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-64cb8d905810>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcocoeval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "# %load pulmonary_embolism.py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import imgaug\n",
    "import json\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "from sampling import gmm_em\n",
    "from sampling import sample\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "\n",
    "class PulmonaryConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"pulmonary\"\n",
    "    # MODEL_TYPE has 2 choices, if you set it as MASK_RCNN, the code will run as the original code on Mask RCNN\n",
    "    # if you set it as P_MASK_RCNN, it will run with P_mask_RCNN mode\n",
    "    MODEL_TYPE = \"P_MASK_RCNN\"\n",
    "    # DOWN_SAMPLE_STRIDE = [4, 8, 16, 32]\n",
    "    # the sample stride for each feature map.\n",
    "    # Notice: the stride should not be set too small, or it will cause memory overflow\n",
    "    DOWN_SAMPLE_STRIDE = [1, 4, 4, 8]\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    UP_SAMPLING_STRATEGY = \"bilinear\"\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    # RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 64\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 2000\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 20\n",
    "\n",
    "    MEAN_PIXEL = np.array([54.18, 54.18, 54.18])\n",
    "\n",
    "\n",
    "class PulmonaryEmbolismDataset(utils.Dataset):\n",
    "    def load_pulmonary_embolism(self, dataset_dir, subset, class_ids=None, return_pul=False):\n",
    "        \"\"\"\n",
    "        :param dataset_dir:  the directory of the dataset\n",
    "        :param subset: the subset of the dataset, Options: train, test, val\n",
    "        :param class_ids: the indexes of the class, default None\n",
    "        :param return_pul: whether to return the generated data set. default False\n",
    "        \"\"\"\n",
    "        pul_emb = COCO(\"{}/annotations/instances_{}.json\".format(dataset_dir, subset))\n",
    "\n",
    "        image_dir = \"{}/{}\".format(dataset_dir, subset)\n",
    "        print(dataset_dir, subset, image_dir)\n",
    "        if not class_ids:\n",
    "            # All classes\n",
    "            class_ids = sorted(pul_emb.getCatIds())\n",
    "        # All images or a subset?\n",
    "        if class_ids:\n",
    "            image_ids = []\n",
    "            for id in class_ids:\n",
    "                image_ids.extend(list(pul_emb.getImgIds(catIds=[id])))\n",
    "            # Remove duplicates\n",
    "            image_ids = list(set(image_ids))\n",
    "        else:\n",
    "            # All images\n",
    "            image_ids = list(pul_emb.imgs.keys())\n",
    "        for i in class_ids:\n",
    "            self.add_class(\"pul_emb\", i, pul_emb.loadCats(i)[0][\"name\"])\n",
    "        for i in image_ids:\n",
    "            # print(pul_emb.imgs[i])\n",
    "            # print(os.path.join(image_dir, pul_emb.imgs[i]['file_name']))\n",
    "            # ann_ids = pul_emb.getAnnIds(imgIds=[i], catIds=class_ids, iscrowd=None)\n",
    "            # print(ann_ids)\n",
    "            # annotations = pul_emb.loadAnns(pul_emb.getAnnIds(imgIds=[i], catIds=class_ids, iscrowd=None))\n",
    "            # print(annotations)\n",
    "            self.add_image(\n",
    "                \"pul_emb\", image_id=i,\n",
    "                path=os.path.join(image_dir, pul_emb.imgs[i]['file_name']),\n",
    "                width=pul_emb.imgs[i][\"width\"],\n",
    "                height=pul_emb.imgs[i][\"height\"],\n",
    "                annotations=pul_emb.loadAnns(pul_emb.getAnnIds(\n",
    "                    imgIds=[i], catIds=class_ids, iscrowd=None)))\n",
    "        # generate the pixels coordinates that will be used to generate anchor\n",
    "        self.generate_sample_points(dataset_dir)\n",
    "        if return_pul:\n",
    "            return pul_emb\n",
    "\n",
    "    def generate_sample_points(self, dataset_dir, subset=\"train\", save_path=\"locations/sample_points.txt\",\n",
    "                               sample_No=1000000):\n",
    "        \"\"\"\n",
    "        :param dataset_dir: the directory of the dataset\n",
    "        :param subset: the subset of the dataset, Options: train, test, val\n",
    "        :param save_path: the path to save the sample points\n",
    "        :param sample_No: the number of sample points\n",
    "        \"\"\"\n",
    "        points = []\n",
    "        # if the sample points file has exist, load it directly\n",
    "        if os.path.exists(save_path):\n",
    "            print(\"load sample points file\")\n",
    "            points = np.loadtxt(save_path)\n",
    "        else:\n",
    "            file_name = \"{}/annotations/instances_{}.json\".format(dataset_dir, subset)\n",
    "            print(\"build GMM and sample points through \" + file_name)\n",
    "            f = open(file_name)\n",
    "            data = json.load(f)\n",
    "            annotations = data[\"annotations\"]\n",
    "            centers = []\n",
    "            # get the center coordinate of each object\n",
    "            for ann in annotations:\n",
    "                bbox = ann[\"bbox\"]\n",
    "                y = bbox[0] + bbox[2] / 2\n",
    "                x = bbox[1] + bbox[3] / 2\n",
    "                centers.append([x, y])\n",
    "            centers = np.asarray(centers)\n",
    "            # build GMM\n",
    "            gmm = gmm_em.GMM(centers)\n",
    "            gmm.em_algorithm(100, 0.0001)\n",
    "            print(\"mu: \", gmm.mu)\n",
    "            print(\"sigma: \", gmm.sigma)\n",
    "            print(\"alpha: \", gmm.alpha)\n",
    "            alpha = np.array(gmm.alpha)\n",
    "            mu = np.array(gmm.mu)\n",
    "            sigma = np.array(gmm.sigma)\n",
    "            print(\"sample from GMM\")\n",
    "            points = sample.sample_from_mixture_gaussian(alpha, mu, sigma, sample_No=sample_No)\n",
    "            np.savetxt(save_path, points, fmt=\"%d\")\n",
    "        # print(points.shape)\n",
    "        self.sample_points = points\n",
    "        return points\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Load instance masks for the given image.\n",
    "\n",
    "        Different datasets use different ways to store masks. This\n",
    "        function converts the different mask format to one format\n",
    "        in the form of a bitmap [height, width, instances].\n",
    "\n",
    "        Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a COCO image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        # print(len(self.image_info))\n",
    "        # print(self.image_info[0])\n",
    "        if image_info[\"source\"] != \"pul_emb\":\n",
    "            return super(PulmonaryEmbolismDataset, self).load_mask(image_id)\n",
    "\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        annotations = self.image_info[image_id][\"annotations\"]\n",
    "        # Build mask of shape [height, width, instance_count] and list\n",
    "        # of class IDs that correspond to each channel of the mask.\n",
    "        for annotation in annotations:\n",
    "            class_id = self.map_source_class_id(\n",
    "                \"pul_emb.{}\".format(annotation['category_id']))\n",
    "            if class_id:\n",
    "                m = self.annToMask(annotation, image_info[\"height\"],\n",
    "                                   image_info[\"width\"])\n",
    "                # Some objects are so small that they're less than 1 pixel area\n",
    "                # and end up rounded out. Skip those objects.\n",
    "                if m.max() < 1:\n",
    "                    continue\n",
    "                # Is it a crowd? If so, use a negative class ID.\n",
    "                if annotation['iscrowd']:\n",
    "                    # Use negative class ID for crowds\n",
    "                    class_id *= -1\n",
    "                    # For crowd masks, annToMask() sometimes returns a mask\n",
    "                    # smaller than the given dimensions. If so, resize it.\n",
    "                    if m.shape[0] != image_info[\"height\"] or m.shape[1] != image_info[\"width\"]:\n",
    "                        m = np.ones([image_info[\"height\"], image_info[\"width\"]], dtype=bool)\n",
    "                instance_masks.append(m)\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "        # Pack instance masks into an array\n",
    "        if class_ids:\n",
    "            mask = np.stack(instance_masks, axis=2).astype(np.bool)\n",
    "            class_ids = np.array(class_ids, dtype=np.int32)\n",
    "            arr = mask.copy().astype(np.int8)\n",
    "            return mask, class_ids\n",
    "        else:\n",
    "            # Call super class to return an empty mask\n",
    "            return super(PulmonaryEmbolismDataset, self).load_mask(image_id)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return a link to the image in the COCO Website.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"pul_emb\":\n",
    "            return \"http://cocodataset.org/#explore?id={}\".format(info[\"id\"])\n",
    "        else:\n",
    "            super(PulmonaryEmbolismDataset, self).image_reference(image_id)\n",
    "\n",
    "    # The following two functions are from pycocotools with a few changes.\n",
    "\n",
    "    def annToRLE(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        segm = ann['segmentation']\n",
    "        s = segm[0]\n",
    "        if isinstance(segm, list):\n",
    "            # polygon -- a single object might consist of multiple parts\n",
    "            # we merge all parts into one mask rle code\n",
    "            rles = maskUtils.frPyObjects(segm, height, width)\n",
    "            rle = maskUtils.merge(rles)\n",
    "        elif isinstance(segm['counts'], list):\n",
    "            # uncompressed RLE\n",
    "            rle = maskUtils.frPyObjects(segm, height, width)\n",
    "        else:\n",
    "            # rle\n",
    "            rle = ann['segmentation']\n",
    "        return rle\n",
    "\n",
    "    def annToMask(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        rle = self.annToRLE(ann, height, width)\n",
    "        m = maskUtils.decode(rle)\n",
    "        return m\n",
    "\n",
    "\n",
    "# class Argument:\n",
    "#     def __init__(self):\n",
    "#         self.command = \"training\"\n",
    "#         self.model = \"coco\"\n",
    "#         self.dataset = \"E:/dataset/pulmonary_embolism\"\n",
    "#         self.logs = os.path.join(ROOT_DIR, \"logs\")\n",
    "#         self.download = False\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "\n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size * cols, size * rows))\n",
    "    return ax\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Train P_Mask R-CNN on PE dataset.')\n",
    "    parser.add_argument(\"command\",\n",
    "                        metavar=\"<command>\",\n",
    "                        help=\"'train' or 'inference'\")\n",
    "    parser.add_argument('--dataset', required=True,\n",
    "                        metavar=\"/path/to/pe/\",\n",
    "                        help='Directory of the PE dataset')\n",
    "    parser.add_argument('--model', required=True,\n",
    "                        metavar=\"/path/to/weights.h5\",\n",
    "                        help=\"Path to weights .h5 file or 'coco'\")\n",
    "    parser.add_argument('--logs', required=False,\n",
    "                        default=DEFAULT_LOGS_DIR,\n",
    "                        metavar=\"/path/to/logs/\",\n",
    "                        help='Logs and checkpoints directory (default=logs/)')\n",
    "    parser.add_argument('--limit', required=False,\n",
    "                        default=500,\n",
    "                        metavar=\"<image count>\",\n",
    "                        help='Images to use for evaluation (default=500)')\n",
    "    parser.add_argument('--download', required=False,\n",
    "                        default=False,\n",
    "                        metavar=\"<True|False>\",\n",
    "                        help='Automatically download and unzip MS-COCO files (default=False)',\n",
    "                        type=bool)\n",
    "    args = parser.parse_args()\n",
    "    print(\"Command: \", args.command)\n",
    "    print(\"Model: \", args.model)\n",
    "    print(\"Dataset: \", args.dataset)\n",
    "    print(\"Logs: \", args.logs)\n",
    "    print(\"Auto Download: \", args.download)\n",
    "    # args = Argument()\n",
    "    # print(\"Command: \", args.command)\n",
    "    # print(\"Model: \", args.model)\n",
    "    # print(\"Dataset: \", args.dataset)\n",
    "    # print(\"Logs: \", args.logs)\n",
    "    # print(\"Auto Download: \", args.download)\n",
    "\n",
    "    dataset_dir = args.dataset\n",
    "    subset = \"train\"\n",
    "    # sample_points_save_path = \"locations/sample_points.txt\"\n",
    "    train_pulmonary = PulmonaryEmbolismDataset()\n",
    "    train_pulmonary.load_pulmonary_embolism(dataset_dir, subset)\n",
    "    # train_pulmonary.generate_sample_points(dataset_dir)\n",
    "    train_pulmonary.prepare()\n",
    "    # print(train_pulmonary.sample_points)\n",
    "\n",
    "\n",
    "    subset = \"val\"\n",
    "    val_pulmonary = PulmonaryEmbolismDataset()\n",
    "    val_pulmonary.load_pulmonary_embolism(dataset_dir, subset)\n",
    "    val_pulmonary.prepare()\n",
    "\n",
    "    subset = \"test\"\n",
    "    test_pulmonary = PulmonaryEmbolismDataset()\n",
    "    test_pulmonary.load_pulmonary_embolism(dataset_dir, subset)\n",
    "    test_pulmonary.prepare()\n",
    "\n",
    "    augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "\n",
    "    MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "    if args.command == \"training\":\n",
    "        config = PulmonaryConfig()\n",
    "\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs, sample_points=train_pulmonary.sample_points)\n",
    "        # COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "        # print(\"Loading weights \", COCO_MODEL_PATH)\n",
    "        # model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "        #                    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "        #                             \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "        # print(\"finish\")\n",
    "        MODEL_PATH = args.model\n",
    "        print(\"Loading weights from \", MODEL_PATH)\n",
    "\n",
    "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "        print(\"finish\")\n",
    "\n",
    "        print(\"Training network heads\")\n",
    "        model.train(train_pulmonary, val_pulmonary,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=20,\n",
    "                    layers='heads',\n",
    "                    augmentation=augmentation)\n",
    "        print(\"finish\")\n",
    "\n",
    "        # Training - Stage 2\n",
    "        # Finetune layers from ResNet stage 4 and up\n",
    "        print(\"Fine tune Resnet stage 4 and up\")\n",
    "        model.train(train_pulmonary, val_pulmonary,\n",
    "                    learning_rate=config.LEARNING_RATE,\n",
    "                    epochs=40,\n",
    "                    layers='4+',\n",
    "                    augmentation=augmentation)\n",
    "\n",
    "        print(\"Fine tune all layers\")\n",
    "        model.train(train_pulmonary, val_pulmonary,\n",
    "                    learning_rate=config.LEARNING_RATE / 10,\n",
    "                    epochs=80,\n",
    "                    layers='all',\n",
    "                    augmentation=augmentation)\n",
    "    elif args.command == \"inference\":\n",
    "        class InferenceConfig(PulmonaryConfig):\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "        inference_config = InferenceConfig()\n",
    "        sample_points = np.loadtxt(\"locations/sample_points.txt\")\n",
    "        model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                                  config=inference_config,\n",
    "                                  model_dir=MODEL_DIR, sample_points=sample_points)\n",
    "        print(model.model_dir)\n",
    "        # model_path = \"../../logs\\pulmonary20190903T1624_standard\\mask_rcnn_pulmonary_0080.h5\"\n",
    "        # model_path = model.find_last()\n",
    "        # MODEL_PATH = \"G:\\longkun\\pythonWorkspace\\Mask_RCNN\\logs\\\\a_pulmonary20190710T1738\\mask_rcnn_pulmonary_0080.h5\"\n",
    "        # MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "        MODEL_PATH = args.model\n",
    "        print(\"Loading weights from \", MODEL_PATH)\n",
    "\n",
    "        model.load_weights(MODEL_PATH, by_name=True)\n",
    "\n",
    "        test_subset = test_pulmonary\n",
    "\n",
    "        APs = []\n",
    "        AP50s = []\n",
    "        AP75s = []\n",
    "        import time\n",
    "\n",
    "        localtime1 = time.time()\n",
    "        for image_id in test_subset.image_ids:\n",
    "            # print(test_subset.image_info[image_id])\n",
    "            original_image, image_meta, gt_class_id, gt_bbox, gt_mask = \\\n",
    "                modellib.load_image_gt(test_subset, inference_config,\n",
    "                                       image_id, use_mini_mask=False)\n",
    "            results = model.detect([original_image], verbose=1)\n",
    "            r = results[0]\n",
    "            AP_50, _, _, _ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"],\n",
    "                                              r[\"class_ids\"], r[\"scores\"], r['masks'], iou_threshold=0.5)\n",
    "            AP_75, _, _, _ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"],\n",
    "                                              r[\"class_ids\"], r[\"scores\"], r['masks'], iou_threshold=0.75)\n",
    "            AP = utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"],\n",
    "                                        r['masks'], verbose=0)\n",
    "            APs.append(AP)\n",
    "            AP50s.append(AP_50)\n",
    "            AP75s.append(AP_75)\n",
    "            print(AP, AP_50, AP_75)\n",
    "            # ax = get_ax(1, 2)\n",
    "            #             # visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id,\n",
    "            #             #                             train_pulmonary.class_names, figsize=(8, 8), ax=ax[0], title=\"real\")\n",
    "            #             # visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],\n",
    "            #             #                             test_subset.class_names, r['scores'], figsize=(8, 8), ax=ax[1], title=\"result\")\n",
    "            #             # plt.show()\n",
    "        localtime2 = time.time()\n",
    "        t = localtime2 - localtime1\n",
    "        print(t, len(test_subset.image_ids), t / len(test_subset.image_ids))\n",
    "        print(\"AP:%f,   AP50:%f,    AP75:%f\" % (np.mean(APs), np.mean(AP50s), np.mean(AP75s)))\n",
    "        print(APs)\n",
    "    else:\n",
    "        print(\"'{}' is not recognized. \"\n",
    "              \"Use 'train' or 'evaluate'\".format(args.command))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Downloading Cython-0.29.23-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Installing collected packages: cython\n",
      "  Attempting uninstall: cython\n",
      "    Found existing installation: Cython 0.29.21\n",
      "    Uninstalling Cython-0.29.21:\n",
      "      Successfully uninstalled Cython-0.29.21\n",
      "Successfully installed cython-0.29.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Cloning https://github.com/philferriere/cocoapi.git to c:\\users\\samwu\\appdata\\local\\temp\\pip-install-o_a90ssx\\pycocotools\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Error [WinError 2] 系統找不到指定的檔案。 while executing command git clone -q https://github.com/philferriere/cocoapi.git 'C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-install-o_a90ssx\\pycocotools'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "pip install \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\SamWu\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - git\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.3               |   py38haa95532_0         2.9 MB\n",
      "    git-2.23.0                 |       h6bb4b03_0        10.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  git                pkgs/main/win-64::git-2.23.0-h6bb4b03_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.10.1-py38haa95532_1 --> 4.10.3-py38haa95532_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.10.3         | 2.9 MB    |            |   0% \n",
      "conda-4.10.3         | 2.9 MB    |            |   1% \n",
      "conda-4.10.3         | 2.9 MB    | 8          |   9% \n",
      "conda-4.10.3         | 2.9 MB    | ##2        |  23% \n",
      "conda-4.10.3         | 2.9 MB    | ###8       |  39% \n",
      "conda-4.10.3         | 2.9 MB    | #####2     |  53% \n",
      "conda-4.10.3         | 2.9 MB    | #######7   |  77% \n",
      "conda-4.10.3         | 2.9 MB    | #########1 |  91% \n",
      "conda-4.10.3         | 2.9 MB    | ########## | 100% \n",
      "\n",
      "git-2.23.0           | 10.5 MB   |            |   0% \n",
      "git-2.23.0           | 10.5 MB   |            |   0% \n",
      "git-2.23.0           | 10.5 MB   |            |   1% \n",
      "git-2.23.0           | 10.5 MB   | 2          |   2% \n",
      "git-2.23.0           | 10.5 MB   | 5          |   5% \n",
      "git-2.23.0           | 10.5 MB   | 7          |   8% \n",
      "git-2.23.0           | 10.5 MB   | #2         |  12% \n",
      "git-2.23.0           | 10.5 MB   | #5         |  15% \n",
      "git-2.23.0           | 10.5 MB   | #7         |  18% \n",
      "git-2.23.0           | 10.5 MB   | ##         |  21% \n",
      "git-2.23.0           | 10.5 MB   | ##3        |  23% \n",
      "git-2.23.0           | 10.5 MB   | ##5        |  25% \n",
      "git-2.23.0           | 10.5 MB   | ##8        |  29% \n",
      "git-2.23.0           | 10.5 MB   | ###2       |  32% \n",
      "git-2.23.0           | 10.5 MB   | ###5       |  36% \n",
      "git-2.23.0           | 10.5 MB   | ###9       |  39% \n",
      "git-2.23.0           | 10.5 MB   | ####4      |  45% \n",
      "git-2.23.0           | 10.5 MB   | ####8      |  48% \n",
      "git-2.23.0           | 10.5 MB   | #####2     |  53% \n",
      "git-2.23.0           | 10.5 MB   | #####9     |  59% \n",
      "git-2.23.0           | 10.5 MB   | ######4    |  64% \n",
      "git-2.23.0           | 10.5 MB   | #######    |  71% \n",
      "git-2.23.0           | 10.5 MB   | #######5   |  76% \n",
      "git-2.23.0           | 10.5 MB   | ########   |  81% \n",
      "git-2.23.0           | 10.5 MB   | ########5  |  85% \n",
      "git-2.23.0           | 10.5 MB   | ########9  |  90% \n",
      "git-2.23.0           | 10.5 MB   | #########4 |  94% \n",
      "git-2.23.0           | 10.5 MB   | #########9 | 100% \n",
      "git-2.23.0           | 10.5 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/philferriere/cocoapi.git to c:\\users\\samwu\\appdata\\local\\temp\\pip-req-build-c5g36j9g\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py): started\n",
      "  Building wheel for pycocotools (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pycocotools\n",
      "Failed to build pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "    Running setup.py install for pycocotools: started\n",
      "    Running setup.py install for pycocotools: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-wheel-twbn4cay'\n",
      "       cwd: C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-c5g36j9g\\PythonAPI\n",
      "  Complete output (13 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  running build_ext\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-c5g36j9g\n",
      "  Complete output (11 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-c5g36j9g\\PythonAPI\\setup.py\", line 25, in <module>\n",
      "      cythonize(ext_modules)\n",
      "    File \"C:\\Users\\SamWu\\anaconda3\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 965, in cythonize\n",
      "      module_list, module_metadata = create_extension_list(\n",
      "    File \"C:\\Users\\SamWu\\anaconda3\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 815, in create_extension_list\n",
      "      for file in nonempty(sorted(extended_iglob(filepattern)), \"'%s' doesn't match any files\" % filepattern):\n",
      "    File \"C:\\Users\\SamWu\\anaconda3\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 114, in nonempty\n",
      "      raise ValueError(error_msg)\n",
      "  ValueError: 'pycocotools/_mask.pyx' doesn't match any files\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for pycocotools\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-record-w7i9kfd9\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\SamWu\\anaconda3\\Include\\pycocotools'\n",
      "         cwd: C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-c5g36j9g\\PythonAPI\n",
      "    Complete output (6 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    running build_ext\n",
      "    building 'pycocotools._mask' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-c5g36j9g\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-record-w7i9kfd9\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\SamWu\\anaconda3\\Include\\pycocotools' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
      "  Cloning https://github.com/philferriere/cocoapi.git to c:\\users\\samwu\\appdata\\local\\temp\\pip-req-build-mgpyqmz5\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py): started\n",
      "  Building wheel for pycocotools (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pycocotools\n",
      "Failed to build pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "    Running setup.py install for pycocotools: started\n",
      "    Running setup.py install for pycocotools: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-wheel-yodbuau6'\n",
      "       cwd: C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-mgpyqmz5\\PythonAPI\n",
      "  Complete output (13 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  running build_ext\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-mgpyqmz5\n",
      "  Complete output (11 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-mgpyqmz5\\PythonAPI\\setup.py\", line 25, in <module>\n",
      "      cythonize(ext_modules)\n",
      "    File \"C:\\Users\\SamWu\\anaconda3\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 965, in cythonize\n",
      "      module_list, module_metadata = create_extension_list(\n",
      "    File \"C:\\Users\\SamWu\\anaconda3\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 815, in create_extension_list\n",
      "      for file in nonempty(sorted(extended_iglob(filepattern)), \"'%s' doesn't match any files\" % filepattern):\n",
      "    File \"C:\\Users\\SamWu\\anaconda3\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 114, in nonempty\n",
      "      raise ValueError(error_msg)\n",
      "  ValueError: 'pycocotools/_mask.pyx' doesn't match any files\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for pycocotools\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-record-u72mmpak\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\SamWu\\anaconda3\\Include\\pycocotools'\n",
      "         cwd: C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-req-build-mgpyqmz5\\PythonAPI\n",
      "    Complete output (6 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    running build_ext\n",
      "    building 'pycocotools._mask' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\SamWu\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\SamWu\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-mgpyqmz5\\\\PythonAPI\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\SamWu\\AppData\\Local\\Temp\\pip-record-u72mmpak\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\SamWu\\anaconda3\\Include\\pycocotools' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
